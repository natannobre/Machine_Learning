{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "1f09bd18c3bd6ca7f9726fc8dcfe1413a5b5683c291aaa94868dd31b44d43b4e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Autor: Natan Nobre Chaves\n",
    "## Atividade 06"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Implemente diferentes funções em Python, usando o NumPy, para calcular:\n",
    "    a) Acurácia\n",
    "    b) Precisão\n",
    "    c) Recall\n",
    "    d) F1-Measure\n",
    "    e) MAE\n",
    "    f) RMSE\n",
    "---\n",
    "Observações:\n",
    "\n",
    "* Cada item acima deve ter uma função própria para calculá-lo.\n",
    "* Todas as funções recebem como parâmetros de entrada y_true e y_pred\n",
    "* As funções para cálculo da Precisão, Recall e F1-Measure devem retornar um único valor já com a métrica calculada baseada na média ponderada das classes.\n",
    "* As funções podem gerar e usar a matriz de confusão usando o scikit learn, mas não podem usar as métricas já implementadas por ele."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tn_fp_fn_tp(y_true, y_pred) :\n",
    "    cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "    qtd_labels = cm.shape[0]\n",
    "    size_each_label = []\n",
    "    tp = [] # True Positives\n",
    "    fp = [] # False Positives\n",
    "    fn = [] # False Negatives\n",
    "    tn = [] # True Negatives\n",
    "\n",
    "    for i in range(qtd_labels) :\n",
    "        size_each_label.append(np.sum(cm[i,:]))\n",
    "        tp.append(cm[i,i])\n",
    "        fp.append(np.sum(cm[:, i]) - cm[i, i])\n",
    "        fn.append(np.sum(cm[i, :]) - cm[i, i])\n",
    "        tn.append(np.sum(cm) - np.sum(cm[i,:]) - np.sum(cm[:, i]))\n",
    "\n",
    "    size_each_label = np.array(size_each_label)\n",
    "    tp = np.array(tp)\n",
    "    fp = np.array(fp)\n",
    "    fn = np.array(fn)\n",
    "    tn = np.array(tn)\n",
    "    #print(cm)\n",
    "\n",
    "    return tn, fp, fn, tp, size_each_label\n",
    "    "
   ]
  },
  {
   "source": [
    "## a) Função da Acurácia"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(y_true, y_pred) :\n",
    "    return np.sum(y_true == y_pred) / y_true.shape[0]"
   ]
  },
  {
   "source": [
    "## b) Função de Precisão"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_precision(y_true, y_pred) :\n",
    "    tn, fp, fn, tp, size = calc_tn_fp_fn_tp(y_true, y_pred)\n",
    "    precision = tp / (tp + fp)\n",
    "    return (np.sum( precision * size) / np.sum(size))"
   ]
  },
  {
   "source": [
    "## c) Função de Recall"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_recall(y_true, y_pred) :\n",
    "    tn, fp, fn, tp, size = calc_tn_fp_fn_tp(y_true, y_pred)\n",
    "    recall = tp / (tp + fn)\n",
    "    return (np.sum( recall * size) / np.sum(size))"
   ]
  },
  {
   "source": [
    "## d) Função F1-Measure"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_f1_measure(y_true, y_pred) :\n",
    "    tn, fp, fn, tp, size = calc_tn_fp_fn_tp(y_true, y_pred)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1_measure = np.divide((2 * precision * recall), (precision + recall), out=np.zeros_like((2 * precision * recall)), where=(precision + recall)!=0)\n",
    "    return (np.sum( f1_measure * size) / np.sum(size)) "
   ]
  },
  {
   "source": [
    "## e) MAE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mae(y_true, y_pred) :\n",
    "    return (np.sum(abs(y_true - y_pred))) / y_true.shape[0]"
   ]
  },
  {
   "source": [
    "## f) RMSE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rmse(y_true, y_pred) :\n",
    "    return (np.sum((y_pred - y_true)**2)/y_true.shape[0])**(1/2)"
   ]
  },
  {
   "source": [
    "## 2. Calcule Acurácia, Precisão, Recall e F1-Measure para sua solução da questão 2 da Lista 04. Caso não tenha feito a questão 2 da Lista 04 terá que fazê-la agora."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv(\"dataset/winequality-white.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = wine['quality'].values\n",
    "X = wine\n",
    "del X['quality']\n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando os dados aleatoriamente em 70%/30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando os modelos kNN\n",
    "quantidade_de_modelos = 1\n",
    "modelokNN = []\n",
    "for idx in range(quantidade_de_modelos) :\n",
    "    modelokNN.append(KNeighborsClassifier(n_neighbors=(idx+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinando o modelo\n",
    "for idx in range(quantidade_de_modelos) :\n",
    "    modelokNN[idx].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for idx in range(quantidade_de_modelos) :\n",
    "    y_pred.append(np.array(modelokNN[idx].predict(X_test)))"
   ]
  },
  {
   "source": [
    "## Acurácia"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5544217687074829\n"
     ]
    }
   ],
   "source": [
    "for idx in range(quantidade_de_modelos) :\n",
    "    print(calc_accuracy(y_test, y_pred[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5544217687074829\n"
     ]
    }
   ],
   "source": [
    "for idx in range(quantidade_de_modelos) :\n",
    "    print(metrics.accuracy_score(y_test, y_pred[idx]))"
   ]
  },
  {
   "source": [
    "## Precisão"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(quantidade_de_modelos) :\n",
    "    print(calc_precision(y_test, y_pred[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(quantidade_de_modelos) :\n",
    "    print(metrics.precision_score(y_test, y_pred[idx], average='weighted', zero_division=0))"
   ]
  },
  {
   "source": [
    "## Recall"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(quantidade_de_modelos) :\n",
    "    print(calc_recall(y_test, y_pred[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(quantidade_de_modelos) :\n",
    "    print(metrics.recall_score(y_test, y_pred[idx], average='weighted', zero_division=0))"
   ]
  },
  {
   "source": [
    "## F1-Measure"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(quantidade_de_modelos) :\n",
    "    print(calc_f1_measure(y_test, y_pred[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(quantidade_de_modelos) :\n",
    "    print(metrics.f1_score(y_test, y_pred[idx], average='weighted', zero_division=0))"
   ]
  },
  {
   "source": [
    "## 3. Calcule MAE e RMSE para sua solução da questão 3.3 da Lista 05. Caso não tenha feito a questão 3.3 da Lista 05 terá que fazê-la agora."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kNNr_model = KNeighborsRegressor(n_neighbors=k)\n",
    "kNNr_model.fit(X_train, y_train)\n",
    "y_pred = kNNr_model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "source": [
    "## MAE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_mae(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "source": [
    "## RMSE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_rmse(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.mean_squared_error(y_test, y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}