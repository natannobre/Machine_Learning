{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd01f09bd18c3bd6ca7f9726fc8dcfe1413a5b5683c291aaa94868dd31b44d43b4e",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 1. Baixe o conjunto de dados Iris (https://www.kaggle.com/uciml/iris):\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\nId                                                                       \n1             5.1           3.5            1.4           0.2  Iris-setosa\n2             4.9           3.0            1.4           0.2  Iris-setosa\n3             4.7           3.2            1.3           0.2  Iris-setosa\n4             4.6           3.1            1.5           0.2  Iris-setosa\n5             5.0           3.6            1.4           0.2  Iris-setosa\n(150, 5)\n"
     ]
    }
   ],
   "source": [
    "# reading iris dataset\n",
    "iris = pd.read_csv(\"dataset/iris.csv\", index_col=0)\n",
    "print(iris.head())\n",
    "print(iris.shape)"
   ]
  },
  {
   "source": [
    "## 2. Exiba a quantidade de amostras existente em cada classe."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iris-setosa: 50 amostras\nIris-virginica: 50 amostras\nIris-versicolor: 50 amostras\n"
     ]
    }
   ],
   "source": [
    "# separated by species\n",
    "type_setosa = iris[iris[\"Species\"] == \"Iris-setosa\"]\n",
    "type_virginica = iris[iris[\"Species\"] == \"Iris-virginica\"]\n",
    "type_versicolor = iris[iris[\"Species\"] == \"Iris-versicolor\"]\n",
    "# number of observations\n",
    "print(\"Iris-setosa: \" + str(type_setosa.shape[0]) + \" amostras\")\n",
    "print(\"Iris-virginica: \" + str(type_virginica.shape[0]) + \" amostras\")\n",
    "print(\"Iris-versicolor: \" + str(type_versicolor.shape[0]) + \" amostras\")"
   ]
  },
  {
   "source": [
    "## 3. Separe aleatoriamente 80% dos dados para treino (conjunto de treino) e 20% dos dados para teste (conjunto de teste). Para esta separação, use somente recursos do Python, Numpy ou Pandas. Não use o Scikit Learn para isso."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "randint() got an unexpected keyword argument 'random_state'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-527-e2caa06fad9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# create 10 random values to set True on the a_train indexes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0ma_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0ma_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: randint() got an unexpected keyword argument 'random_state'"
     ]
    }
   ],
   "source": [
    "# list to separete train data (80% - 120 observations) and test data (20% - 30 observations)\n",
    "a_test = np.array([False]*50)\n",
    "index = 0\n",
    "while index < 10 :\n",
    "    num = np.random.randint(0,50, random_state=1) # create 10 random values to set True on the a_train indexes\n",
    "    if a_test[num] == False :\n",
    "        a_test[num] = True\n",
    "        index += 1\n",
    "\n",
    "# create a test dataframe with 30 observations\n",
    "test_data = pd.concat([type_setosa[a_test], type_versicolor[a_test], type_virginica[a_test]])\n",
    "\n",
    "# invert all values of a_train to crate the test dataframe\n",
    "a_train = np.invert(a_test)\n",
    "\n",
    "# create a train dataframe with 120 observations\n",
    "train_data = pd.concat([type_setosa[a_train], type_versicolor[a_train], type_virginica[a_train]])\n",
    "\n",
    "print(train_data)\n",
    "print(train_data.shape)\n",
    "print(test_data)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize the test and train data\n",
    "test_data = test_data.sample(frac=1, random_state=42)\n",
    "train_data = train_data.sample(frac=1, random_state=42)\n",
    "#print(test_data)\n",
    "#print(train_data)"
   ]
  },
  {
   "source": [
    "## 4. Usando somente o conjunto de treino, mostre as médias dos valores de cada feature para cada classe."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
       "Species                                                                  \n",
       "Iris-setosa             5.0250        3.4375         1.4575        0.2350\n",
       "Iris-versicolor         5.9850        2.7875         4.2950        1.3525\n",
       "Iris-virginica          6.5975        3.0225         5.5675        2.0500"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SepalLengthCm</th>\n      <th>SepalWidthCm</th>\n      <th>PetalLengthCm</th>\n      <th>PetalWidthCm</th>\n    </tr>\n    <tr>\n      <th>Species</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Iris-setosa</th>\n      <td>5.0250</td>\n      <td>3.4375</td>\n      <td>1.4575</td>\n      <td>0.2350</td>\n    </tr>\n    <tr>\n      <th>Iris-versicolor</th>\n      <td>5.9850</td>\n      <td>2.7875</td>\n      <td>4.2950</td>\n      <td>1.3525</td>\n    </tr>\n    <tr>\n      <th>Iris-virginica</th>\n      <td>6.5975</td>\n      <td>3.0225</td>\n      <td>5.5675</td>\n      <td>2.0500</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 451
    }
   ],
   "source": [
    "train_data.groupby(\"Species\").mean()"
   ]
  },
  {
   "source": [
    "## 5. Crie um algoritmo seu (sem usar aprendizado de máquina) para baseado nas médias das features calculadas no item 4, ou mesmo usando outras ideias suas, classificar corretamente as amostras do conjunto de teste. Aperfeçoe o seu algoritmo de forma a obter melhores resultados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
       "count     120.000000    120.000000     120.000000    120.000000\n",
       "mean        5.869167      3.082500       3.773333      1.212500\n",
       "std         0.829072      0.433989       1.776681      0.777149\n",
       "min         4.400000      2.000000       1.000000      0.100000\n",
       "25%         5.200000      2.800000       1.500000      0.300000\n",
       "50%         5.800000      3.000000       4.350000      1.300000\n",
       "75%         6.400000      3.400000       5.100000      1.800000\n",
       "max         7.900000      4.400000       6.900000      2.500000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SepalLengthCm</th>\n      <th>SepalWidthCm</th>\n      <th>PetalLengthCm</th>\n      <th>PetalWidthCm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>120.000000</td>\n      <td>120.000000</td>\n      <td>120.000000</td>\n      <td>120.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.869167</td>\n      <td>3.082500</td>\n      <td>3.773333</td>\n      <td>1.212500</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.829072</td>\n      <td>0.433989</td>\n      <td>1.776681</td>\n      <td>0.777149</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4.400000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.100000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.200000</td>\n      <td>2.800000</td>\n      <td>1.500000</td>\n      <td>0.300000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.800000</td>\n      <td>3.000000</td>\n      <td>4.350000</td>\n      <td>1.300000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.400000</td>\n      <td>3.400000</td>\n      <td>5.100000</td>\n      <td>1.800000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.900000</td>\n      <td>4.400000</td>\n      <td>6.900000</td>\n      <td>2.500000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 452
    }
   ],
   "source": [
    "# Analyze correlation between the features\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "def personal_classifier(df_test:pd.DataFrame):\n",
    "    '''\n",
    "    Parameters: df_test = pandas.DataFrame (test dataset).\n",
    "    Return: numpy.Array = [\"Iris_setosa\", \"Iris_versicolor\" ou \"Iris_virginica\"] (classification type).\n",
    "    '''\n",
    "\n",
    "    classification = \"\"\n",
    "\n",
    "    train_petal_info = train_data.groupby(\"Species\").mean()\n",
    "    print(train_petal_info)\n",
    "    train_petal_info = train_petal_info[[\"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "    np_train_petal_lenght = np.array(train_petal_info.iloc[:, 0])\n",
    "    np_train_petal_width = np.array(train_petal_info.iloc[:, 1])\n",
    "    #print(np_train_petal_lenght)\n",
    "    #print(train_petal_info)\n",
    "\n",
    "    test_petal_info = df_test[[\"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "    np_test_petal_lenght = np.array(test_petal_info.iloc[:, 0])\n",
    "    np_test_petal_width = np.array(test_petal_info.iloc[:, 1])\n",
    "    #print(np_test_petal_lenght)\n",
    "\n",
    "    l_train = []\n",
    "\n",
    "    # Setosa test\n",
    "    train = np_train_petal_lenght[0]\n",
    "    for test in np_test_petal_lenght :\n",
    "        l_train.append([abs(train - test), \"Iris-setosa\"])\n",
    "    \n",
    "    # Versicolor test\n",
    "    index = 0\n",
    "    train = np_train_petal_lenght[1]\n",
    "    for test in np_test_petal_lenght :\n",
    "        if (abs(train - test) < l_train[index][0]) :\n",
    "            l_train[index] = [abs(train - test), \"Iris-versicolor\"]\n",
    "        index += 1\n",
    "    \n",
    "    # Virginica test\n",
    "    index = 0\n",
    "    train = np_train_petal_lenght[2]\n",
    "    for test in np_test_petal_lenght :\n",
    "        if (abs(train - test) < l_train[index][0]) :\n",
    "            l_train[index] = [abs(train - test), \"Iris-virginica\"]\n",
    "        index += 1\n",
    "    \n",
    "    np_l_train = np.array(l_train)\n",
    "    return np_l_train[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\nSpecies                                                                  \nIris-setosa             5.0250        3.4375         1.4575        0.2350\nIris-versicolor         5.9850        2.7875         4.2950        1.3525\nIris-virginica          6.5975        3.0225         5.5675        2.0500\n['Iris-virginica' 'Iris-versicolor' 'Iris-virginica' 'Iris-versicolor'\n 'Iris-setosa' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'\n 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n 'Iris-setosa' 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica'\n 'Iris-setosa' 'Iris-setosa' 'Iris-virginica' 'Iris-setosa'\n 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica'\n 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor' 'Iris-versicolor'\n 'Iris-versicolor' 'Iris-setosa']\n"
     ]
    }
   ],
   "source": [
    "predicted_values = personal_classifier(test_data)\n",
    "print(predicted_values)"
   ]
  },
  {
   "source": [
    "## 6. Quanto por cento no conjunto de teste você conseguiu acertar corretamente o rótulo (classe) no seu melhor algoritmo, ou seja, qual a acurácia?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "96.67 %\n"
     ]
    }
   ],
   "source": [
    "def personal_evaluation(real_values, predicted_values) :\n",
    "    count = 0\n",
    "    for index in range(30) :\n",
    "        if real_values[index] == predicted_values[index] :\n",
    "            count += 1\n",
    "        #print(real_values[index], predicted_values[index])\n",
    "            \n",
    "    return round(count*100 / real_values.shape[0], 2)\n",
    "    \n",
    "\n",
    "real_values = np.array(test_data[\"Species\"])\n",
    "evaluation = personal_evaluation(real_values, predicted_values)\n",
    "print(str(evaluation) + \" %\")"
   ]
  }
 ]
}